# 面试记录

## 2024.6.4(中国商飞一面)

#### 自我介绍

​		面试官您好！我叫刘洲岩，今年25岁，2021年毕业于中国传媒大学，本科学习的是信息安全专业。刚毕业没有从事工作是因为在考研，第一份工作在武汉，因为女朋友在成都，所以和家人商量之后就来了成都，目前看工作地点比较稳定，决定扎根成都发展。

​		上一份工作是在神州绿盟，具体工作内容偏向于网关类安全产品的开发，我们做的项目具体是给工信部提供一个工业互联网僵木蠕检测平台，因为每年工信部对电信企业有拨测考核，通过拨测专用软件向拨测靶机上下载各类恶意样本，通过部署我们的设备，把运营商主干网的数据流量镜像到我们的TDC设备进行检测，通过对检测率进行统计来确定拨测是否合格。

​		整个系统架构其实主要就是一个server负责流量的实时采集：就是进行数据包的抓取、解析、分发、这里是依赖dpdk基础驱动，实现高速抓包**（因为dpdk是通过用户态的网络协议栈，绕过内核网络栈以实现高性能的数据包处理，绑定网卡，然后通过一个轮询的机制来收集数据包，将数据包解析后存储rte_ring这样的环形缓冲区，构建生产者-消费者的关系，）**协议解析完成了2-4层数据包的解析、然后通过dpdk的rte_ring把数据包分发到多个class，我的class就是进行安全检测，最后通过Webtoid这样一个数据外发的接口，上报告警信息。

​		我们的设备除了能集中管理（就是一个省统一部署多套僵木蠕TDC，统一进行配置修改或者升级），还得支持协同联动场景（可以根据上级管理平台下发的针对恶意流量的检测指令，来产生相关的告警，并将检测的日志和样本信息回传给上级管理平台），然后我这边做的检测功能主要就是需要归并上级平台下发的检测规则，提取专包中相关的关键字，来匹配分发的数据包中的特征信息，但是当时因为有多个不同的Class中有不同的检测模块，有的是挖矿检测、有的是APT检测、还要勒索检测，但是每次下发的检测规则都一样，导致每次都得加载同样的内容、比较占用内存，然后就看了一下刚好用了dpdk嘛，就用hugepages优化了一下，只让一个模块加载规则，然后通过共享内存池来实现进程间的通信；包括其实各类情报在检测匹配的时候也是通过hash碰撞的方法，就是拿到一条规则，比如提取他的ip或者url然后算个hash值存起来跟之后的检测对象hash值进行对比，然后通过上述的一个共享方法，这样也可以做到统一hash，对内存使用率也起到了优化作用。

​		之后检测过程中，如果成功命中规则，通过cJson序列化一条告警信息，交给webtoid数据外发接口。但是因为我们是旁路部署嘛，所以还需要发送一条TCP RESET数据帧到主网，来实现旁路阻断。



​		然后之前在武汉的工作是在做一个私有云存储管理系统，整个项目是基于Workflow异步框架开发的webserver，Workflow把实际的业务逻辑按照流程图的形式分解成一个一个的任务，每个任务执行时会分为两个阶段：首先是根据任务的类型完成基本工作，待基本工作完成之后，就会执行一个回调函数。任务之间可以同步地串行执行，多个任务也可以同时异步地并行执行。

​		比如在这里作为一个HttpServer，首先创建一个httpserver服务，配置基础配置，初始化线程池内存池以及调度器轮询器，开始listen，当有客户端请求连接时调用accept的callback函数，为新的连接创建 `WFHttpTask` 任务。然后任务被事件循环调度执行。比如解析 HTTP 请求。调用用户定义的处理函数来处理请求。生成并发送 HTTP 响应等，当然在整个httpserver服务中间还可以去并行或者串行其它的任务：比如作为mysql客户端发送查询请求，或者进行文件的IO；

​		在这里我配合前端的同学，来商定接口，实现用户登录注册的功能。因为说实话这个workflow异步编程虽然效率比较高，但是写代码非常反人类，所以后来还是用了WFrest来提供比较简单易用的API，不需要再去过于关注整个模块的执行流程，这样只需要将HTTP对应的请求方法、路径参数、查询参数进行注册，当触发某个请求时，就会自动走这个流程。用户登录注册这里是Mysql维护一个用户数据表和一个用户token表，每次登录时，服务器接收到登录请求后，验证用户提供的用户名和密码。如果验证成功，服务器生成一个 token，存入token表。

​		在上传文件的时候，假如文件的体积过大，就会导致单次传输时间过长，传输失败的风险大大增加。为了使传输过程更加灵活；将要上传的文件切分成 若干小片，每个小片单独传输，服务端会接收某个文件的若干小片，最后合并这些分片以获取原始文件。1、在执行真正的上传操作之前，必须为每个文件上传任务分配一个上传ID，服务端可以通过ID识别不同的文件任务；除了需要生成上传ID以外，服务端还需要根据文件的体积和其他信息，生成分块相关的数据返回给客户 端，并且存入缓存当中**（本项目当中使用redis作为缓存，这里键选用上传ID，值 数据类型是哈希表）**2、由于不同的接口会使用相同的URL路径部分进行上传，所以需要在URL的查询部分来携带上传ID和分片 信息。因此该接口的第一步是解析用户请求。3、最后一个接口需要完成的操作是获取上传进度，然后检查所有分片是否都已经上传完成，如果所有都已 经上传完成了，则执行合并操作。

​		上传文件完成后为了实现备份、也是直接用了aliyun的oss来做二次备份，但是开始设计的时候因为上传业务和备份业务是串行在一起的，为了不影响用户上传文件的体验，提升上传效率，也是对上传备份两个不相关的业务逻辑进行了解耦，引入了一个消息队列RabbitMQ作为aliyun和本地server的中间层。

#### Question

##### 1、 Makefile

​	如何编写Makefile能够使其拓展性更强，在目录中新增头文件源文件后，不需要修改Makefile文件？

```makefile
#定义变量
SRCDIR = src
OBJDIR = obj
BINDIR = bin
TARGET = $(BINDIR)/myprogram

#编译器选项
CC = g++
CFLAGS = -Wall -g -pthread

#查找源文件和目标文件
SOURCES = $(wildcard $(SRCDIR)/*.cc)
OBJECTS = $(patsubst $(SRCDIR)/%.cc, $(OBJDIR)/%.o, $(SOURCES))

#一层依赖一层（可执行程序依赖目标文件链接，目标文件依赖源文件编译）

#默认目标
all: $(TARGET)

#链接目标文件生成可执行文件
$(TARGET): $(OBJECTS)
	@echo "Linking..."
	@mkdir -p $(BINDIR)
	$(CC) $^ -o $@

#编译源文件为目标文件
$(OBJDIR)/%.o: $(SRCDIR)/%.cc
	@echo "Comliling $<..."
	@mkdir -p $(OBJDIR)
	$(CC) -c $< -o $@ $(CFLAGS)

#清理目标文件和可执行文件
.PHONY: clean
clean:
	rm -rf $(OBJDIR)/*.o $(BINDIR)/myprogram

# 打印变量值（调试用）
.PHONY: show_vars
show_vars:
	@echo "SOURCES: $(SOURCES)"
	@echo "OBJECTS: $(OBJECTS)"

```

**增强makefile拓展性：**
	   1、多使用变量（用变量来存储文件名、目录名、编译器选项等信息，以便在整个 Makefile 中重复使用，并且方便在将来进行修改）

​		2、使用内置函数（比如wildcard、patsubst来构建文件列表，使得 Makefile 更加灵活和可扩展）

​		3、使用模式规则（定义通用的编译规则，以便支持不同类型的源文件，%.o: %.cc）

​		4、使用自动变量

```makefile
		$@  # 规则中的目标文件名
		$^  # 规则中的所有依赖文件名，以空格分隔
		$<  # 规则中的第一个依赖文件名
```

​			  

##### 2、include中""和<>的区别

​	1、include"":

​			用途：通常用于包含项目中自定义的头文件

​			搜索顺序：编译器先在当前文件的目录中查找头文件；如果在当前文件目录中找不到该头文件，再按照标准头文件路径去搜索，通常包括用户指定的目录和标准库目录。

​	2、include<>：

​		    用途：通常用于包含标准库头文件或者第三方库的文件

​			搜索顺序：编译器直接在标准头文件搜索路径中查找头文件，这些路径路径通常包括编译器和标准头文件目录

##### 3、TCP滑动窗口，滑动窗口为了解决什么问题?

##### 4、了解qt中的信号槽吗?

##### 5、用过qt哪些组件?

##### 6、用过哪些STL容器？了解他们底层数据结构和区别吗？(具体问了vector、list、map)















### 

​		

